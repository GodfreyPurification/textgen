{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba980fd",
   "metadata": {},
   "outputs": [],
   "source": [
   
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57ad2a5e",
   "metadata": {},
   "outputs": [],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de4e2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\jupyterlab\\BetterzilAIModel\\aimodelvenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import pickle \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from tensorflow.keras.models import Sequential, load_model \n",
    "from tensorflow.keras.layers import LSTM, Dense,Activation \n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "155b87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df=pd.read_csv('../BetterzilAIModel/fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ee7469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=list(text_df.text.values)\n",
    "joined_text=\"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bddf6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_text=joined_text[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1e7d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "tokens = tokenizer.tokenize(partial_text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77b7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tokens=np.unique(tokens)\n",
    "unique_token_index= {token: idx for idx,token in enumerate(unique_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b8ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words =10\n",
    "input_words=[]\n",
    "next_words= []\n",
    "\n",
    "for i in range(len(tokens) - n_words):\n",
    "    input_words.append(tokens[i:i +n_words])\n",
    "    next_words.append(tokens[i + n_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6016093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.zeros((len(input_words), n_words,len(unique_tokens)), dtype=bool)\n",
    "y= np.zeros((len(next_words), len(unique_tokens)),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5362b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, words in enumerate(input_words): \n",
    "    for j, word in enumerate(words):\n",
    "        x[i, j, unique_token_index[word]] = 1\n",
    "    y[i, unique_token_index[next_words[i]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48c504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\jupyterlab\\BetterzilAIModel\\aimodelvenv\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model =Sequential()\n",
    "model.add(LSTM(128, input_shape=(n_words, len(unique_tokens)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(unique_tokens)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af39ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From E:\\jupyterlab\\BetterzilAIModel\\aimodelvenv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\jupyterlab\\BetterzilAIModel\\aimodelvenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "14/14 [==============================] - 10s 83ms/step - loss: 6.2013 - accuracy: 0.0423\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 5.8504 - accuracy: 0.0617\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 5.7960 - accuracy: 0.0617\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 1s 75ms/step - loss: 5.7658 - accuracy: 0.0617\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 1s 78ms/step - loss: 5.7269 - accuracy: 0.0617\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 1s 85ms/step - loss: 5.6687 - accuracy: 0.0617\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 1s 74ms/step - loss: 5.5952 - accuracy: 0.0617\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 1s 77ms/step - loss: 5.4877 - accuracy: 0.0635\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 1s 81ms/step - loss: 5.3493 - accuracy: 0.0738\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 1s 79ms/step - loss: 5.1557 - accuracy: 0.0812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x139a6305810>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01),metrics=[\"accuracy\"])\n",
    "model.fit(x,y,batch_size=128, epochs=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "402b7558",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"E:\\jupyterlab\\BetterzilAIModel\\model\\mymodel.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec5f688",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('E://jupyterlab//BetterzilAIModel//model//mymodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c7c3b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text,n_best):\n",
    "    input_text=input_text.lower()\n",
    "    x=np.zeros((1,n_words, len(unique_tokens)))\n",
    "    for i, word in enumerate(input_text.split()):\n",
    "        x[0,i,unique_token_index[word]]=1\n",
    "    predictions=model.predict(x)[0]\n",
    "    return np.argpartition(predictions, n_best)[n_best:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3232933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "possible=predict_next_word(\"He will have to look into this thing and he\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b0bd2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([325, 251, 533, 481, 391, 135, 450, 130, 516, 328, 363, 361, 493,\n",
       "       161, 136,   3, 431, 456, 539, 542,   1, 322, 258, 255, 501, 574,\n",
       "       375, 598, 376, 601, 237, 423, 348, 234, 678, 462, 459, 426, 460,\n",
       "       464,  45, 449, 445, 438, 473, 477, 479,  52, 418,  34, 386, 492,\n",
       "       498, 373, 369, 364, 499, 502,  25, 345, 339, 537,  67, 547, 548,\n",
       "       555, 563,  16, 609, 625, 235, 634,  77, 637, 224, 200, 188,  82,\n",
       "       181, 169, 641, 163, 162, 647, 151, 141, 140, 139, 653, 672, 684,\n",
       "        96, 118, 116, 115, 101, 697, 102, 103, 104, 105, 106, 107, 108,\n",
       "       109, 100, 111, 112, 113, 114,  99,  98, 117,  97, 119, 120, 121,\n",
       "       122, 123, 124, 125, 126, 127, 128, 129,  95, 131, 132, 133, 134,\n",
       "        94,  93, 137, 138,  92,  91,  90, 142, 143, 144, 145, 146, 147,\n",
       "       148, 149, 150,  89, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
       "        88,  87,  86, 164, 165,  85, 167, 168,  84, 170, 171, 172, 173,\n",
       "       174, 175, 176, 177, 178, 179, 180,  83, 182, 183, 184, 185, 186,\n",
       "       187,  81, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
       "        80, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "       213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,  79, 225,\n",
       "       226, 227, 228, 229, 230, 231, 232,  78,  76,  75, 236,  74, 238,\n",
       "       239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250,  73,\n",
       "       252, 253, 254,  72, 256, 257,  71, 259, 260, 261, 262, 263, 264,\n",
       "       265, 266,  70, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "       278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "       291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "       304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "       317, 318, 319, 320, 321,  69, 323, 324,  68, 326, 327,  66, 329,\n",
       "       330, 331, 332, 333, 334, 335, 336, 337, 338,  65, 340, 341, 342,\n",
       "       343, 344,  64, 346, 347,  63, 349, 350, 351, 352, 353, 354, 355,\n",
       "       356, 357, 358, 359, 360,  62, 362,  61,  60, 365, 366, 367, 368,\n",
       "        59, 370, 371, 372,  58, 374,  57,  56, 377, 378, 379, 380, 381,\n",
       "       382, 383, 384, 385,  55, 387, 388, 389, 390,  54, 392, 393, 394,\n",
       "       395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "       408, 409, 410, 411, 412, 413, 414, 415, 416, 417,  53, 419, 420,\n",
       "       421, 422,  51, 424, 425,  50, 427, 428, 429, 430,  49, 432, 433,\n",
       "       434, 435, 436, 437,  48, 439, 440, 441, 442, 443, 444,  47, 446,\n",
       "       447, 448,  46,  44, 451, 452, 453, 454, 455,  43, 457, 458,  42,\n",
       "        41, 461,  40, 463,  39, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "        38, 474, 475, 476,  37, 478,  36, 480,  35, 482, 483, 484, 485,\n",
       "       486, 487, 488, 489, 490, 491,  33,  32, 494, 495, 496, 497,  31,\n",
       "        30, 500,  29,  28, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "       512, 513, 514, 515,  27, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "       525, 526, 527, 528, 529, 530, 531,  26,  24, 534, 535, 536,  23,\n",
       "       538,  22, 540, 541,  21, 543, 544, 545, 546,  20,  19, 549, 550,\n",
       "       551, 552, 553, 554,  18, 556, 557, 558, 559, 560, 561, 562,  17,\n",
       "       564, 565, 566, 567, 568, 569, 570, 571, 572, 573,  15, 575, 576,\n",
       "       577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589,\n",
       "       590, 591, 592, 593, 594, 595, 596, 597,  14, 599, 600,  13, 602,\n",
       "       603, 604, 605, 606, 607, 608,  12, 610, 611, 612, 613, 614, 615,\n",
       "       616, 617, 618, 619, 620, 621, 622, 623, 624,  11, 626, 627, 628,\n",
       "       629, 630, 631, 632, 633,  10, 635, 636,   9, 638, 639, 640,   8,\n",
       "       642, 643, 644, 645, 646,   7, 648, 649, 650, 651, 652,   6, 654,\n",
       "       655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
       "       668, 669, 670, 671,   5, 673, 674, 675, 676, 677,   4, 679, 680,\n",
       "       681, 682, 683,   2, 685, 686, 687, 688, 689, 690, 691, 692, 693,\n",
       "       694, 695, 696,   0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "498d9004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['journalism', 'freedom', 'short', 'reality', 'nice', 'comment', 'preemptively', 'column', 'savage', 'keep', 'major', 'lynch', 'replaced', 'criminal', 'compared', '60', 'personal', 'principled', 'smart', 'sniveling', '2020', 'j', 'given', 'futures', 'reveal', 'surreal', 'miles', 'threat', 'misguided', 'thrown', 'figurehead', 'paranoid', 'limp', 'few', 'wiretaps', 'prominent', 'pro', 'pass', 'procedural', 'protecting', 'appeaser', 'preemptive', 'possible', 'plan', 'quickly', 'rating', 'react', 'asked', 'outcome', 'americans', 'navigate', 'remind', 'respond', 'mess', 'match', 'make', 'results', 'revelation', 'ahead', 'lie', 'leadership', 'sigh', 'bad', 'speaks', 'spectrum', 'start', 'strange', 'ads', 'trapped', 'unfavorable', 'fight', 'usual', 'behind', 'vast', 'explanations', 'editorial', 'digg', 'better', 'desperate', 'debate', 'violation', 'currently', 'cunning', 'wake', 'country', 'conspiracy', 'conspiracies', 'conservative', 'warning', 'whole', 'word', 'bureau', 'claiming', 'claim', 'circulated', 'calling', 'zero', 'came', 'campaign', 'can', 'candidate', 'cards', 'career', 'careers', 'carville', 'cable', 'chances', 'changed', 'charge', 'chilly', 'by', 'but', 'claimed', 'buried', 'classified', 'clearly', 'clinton', 'clintons', 'clintonworld', 'close', 'closing', 'cnn', 'co', 'collapsed', 'colleagues', 'bring', 'com', 'coma', 'come', 'comey', 'bribery', 'breezy', 'computer', 'confident', 'breeze', 'breathing', 'bragged', 'continue', 'control', 'conviction', 'coordinating', 'corrected', 'corruption', 'could', 'couldn', 'countless', 'boston', 'courage', 'course', 'cover', 'covert', 'cowardice', 'coy', 'cravenly', 'credibility', 'crime', 'born', 'boldly', 'bizarre', 'cycle', 'damaging', 'bigotry', 'day', 'days', 'bigger', 'decided', 'decides', 'declare', 'declared', 'declaring', 'defending', 'delicious', 'democratic', 'democrats', 'denial', 'deny', 'between', 'desperately', 'desperation', 'destroy', 'development', 'did', 'didn', 'believing', 'director', 'display', 'dnc', 'do', 'doj', 'don', 'done', 'dosed', 'down', 'during', 'edgar', 'believes', 'either', 'elect', 'election', 'else', 'email', 'emailing', 'emails', 'endorsement', 'energy', 'enjoys', 'enough', 'entire', 'especially', 'establishment', 'even', 'ever', 'every', 'everyone', 'exactly', 'example', 'exist', 'existence', 'explanation', 'belief', 'explosively', 'exposed', 'exposing', 'fairly', 'fbi', 'fear', 'federal', 'feigned', 'being', 'behavior', 'before', 'fighting', 'been', 'filled', 'film', 'final', 'finding', 'fire', 'fireworks', 'flailing', 'focused', 'focusing', 'followed', 'for', 'form', 'foundation', 'beds', 'from', 'front', 'fundamental', 'becoming', 'gasoline', 'gave', 'be', 'glancing', 'globe', 'go', 'going', 'gone', 'good', 'google', 'got', 'bathroom', 'hacks', 'had', 'happened', 'hard', 'harry', 'has', 'hatch', 'hates', 'have', 'he', 'head', 'headline', 'hell', 'her', 'here', 'hillary', 'him', 'himself', 'his', 'hit', 'home', 'hoover', 'hope', 'hospital', 'hour', 'house', 'how', 'however', 'https', 'hubris', 'huma', 'hurt', 'idea', 'if', 'illegal', 'illegality', 'impropriety', 'in', 'information', 'insane', 'insisted', 'instant', 'instead', 'interesting', 'intimidation', 'into', 'investigation', 'investigators', 'irritating', 'is', 'islam', 'isn', 'it', 'its', 'batch', 'james', 'jobs', 'badly', 'just', 'justified', 'backed', 'keeping', 'kgb', 'kind', 'knew', 'know', 'lambasting', 'lash', 'last', 'latest', 'lead', 'back', 'leave', 'led', 'left', 'letter', 'level', 'awkwardly', 'lies', 'like', 'awkward', 'linkedin', 'lit', 'lived', 'loaded', 'locked', 'lofty', 'long', 'longer', 'look', 'lot', 'loyalists', 'lunatic', 'away', 'made', 'attacking', 'attacked', 'making', 'man', 'manages', 'many', 'attack', 'may', 'meant', 'media', 'at', 'might', 'assume', 'associates', 'mob', 'moment', 'months', 'moral', 'more', 'most', 'msnbc', 'much', 'mysterious', 'assaults', 'near', 'never', 'new', 'news', 'assaulting', 'no', 'nobody', 'nominee', 'nonsense', 'not', 'nothing', 'november', 'now', 'numerous', 'obama', 'of', 'off', 'often', 'old', 'on', 'once', 'one', 'only', 'operation', 'opponent', 'option', 'or', 'original', 'other', 'ought', 'out', 'assault', 'outdone', 'over', 'own', 'panicked', 'as', 'particularly', 'party', 'article', 'patients', 'paul', 'payroll', 'people', 'arrogant', 'pic', 'picked', 'picking', 'pieces', 'pinterest', 'place', 'around', 'playing', 'pocket', 'political', 'politics', 'poses', 'positive', 'are', 'postured', 'power', 'practically', 'approach', 'appearing', 'president', 'presidential', 'pretend', 'pretending', 'previously', 'appeared', 'principles', 'print', 'appearance', 'apolitical', 'procedure', 'anywhere', 'promising', 'any', 'proved', 'public', 'published', 'pure', 'push', 'putin', 'question', 'questions', 'anthony', 'radical', 'rally', 'ranks', 'announced', 're', 'and', 'realdonaldtrump', 'an', 'really', 'reason', 'recalls', 'recover', 'reddit', 'refused', 'reid', 'relevance', 'relief', 'remembered', 'amendment', 'also', 'republican', 'republicans', 'resignation', 'respected', 'already', 'allowed', 'retired', 'allies', 'allegations', 'reversed', 'review', 'ride', 'rigged', 'right', 'ringing', 'risk', 'rodham', 'role', 'running', 'ryan', 's', 'same', 'all', 'says', 'scandal', 'scandals', 'scene', 'screwed', 'security', 'seemed', 'senator', 'senior', 'sent', 'server', 'setup', 'sexism', 'sexual', 'she', 'alive', 'ago', 'shove', 'shown', 'shrugged', 'agents', 'slightest', 'agency', 'smell', 'smoke', 'age', 'so', 'space', 'speaker', 'speakerryan', 'against', 'afternoon', 'spinelessness', 'spinmeisters', 'spouting', 'stage', 'staggering', 'stand', 'after', 'statement', 'states', 'stay', 'step', 'still', 'stored', 'stories', 'afraid', 'strategy', 'stretch', 'struggle', 'stumbleupon', 'substance', 'such', 'sudden', 'suddenly', 'supporting', 'surprising', 'admits', 'survival', 't', 'table', 'tak', 'taking', 'talked', 'tape', 'targeting', 'television', 'tells', 'tenth', 'than', 'that', 'the', 'their', 'them', 'then', 'there', 'they', 'thing', 'this', 'those', 'thought', 'ad', 'through', 'throughout', 'act', 'tied', 'time', 'times', 'to', 'today', 'too', 'train', 'accusing', 'trash', 'truly', 'trump', 'truths', 'try', 'trying', 'tumblr', 'turned', 'twitter', 'two', 'ugly', 'unapologetic', 'uncomfortable', 'under', 'underway', 'accused', 'unite', 'united', 'unprecedented', 'unscathed', 'until', 'up', 'us', 'used', 'abuses', 'utter', 'value', 'aboutface', 'very', 'victory', 'violating', 'about', 'vladimir', 'volumes', 'vote', 'voted', 'vytt49yvoe', 'abedin', 'waking', 'want', 'wants', 'war', 'warned', 'abcpolitics', 'was', 'watching', 'way', 'wcvscg4a5i', 'weathered', 'weeks', 'weiner', 'well', 'went', 'were', 'what', 'whatever', 'when', 'where', 'whether', 'which', 'while', 'who', 'abc', 'whose', 'why', 'wikipedia', 'will', 'wing', 'a', 'wisconsin', 'with', 'within', 'without', 'women', '5', 'world', 'would', 'wouldn', 'wound', 'wreck', 'wreckage', 'writer', 'wrong', 'years', 'york', 'you', 'your', '2016']\n"
     ]
    }
   ],
   "source": [
    "print([unique_tokens[idx] for idx in possible])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "577f5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(input_text, text_length, creativity=3):\n",
    "    word_sequence = input_text.split()\n",
    "    current = 0\n",
    "    for _ in range(text_length):\n",
    "        sub_sequence=\" \".join(tokenizer.tokenize(\"\".join(word_sequence).lower())[current:current+n_words])\n",
    "        try: \n",
    "            choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
    "        except:\n",
    "            choice=random.choice(unique_tokens)\n",
    "        word_sequence.append(choice)\n",
    "        current  +=1\n",
    "    return\" \".join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39eb9a63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(input_text, text_length, creativity)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[1;32m----> 7\u001b[0m     choice \u001b[38;5;241m=\u001b[39m unique_tokens[random\u001b[38;5;241m.\u001b[39mchoice(\u001b[43mpredict_next_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreativity\u001b[49m\u001b[43m)\u001b[49m)]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m, in \u001b[0;36mpredict_next_word\u001b[1;34m(input_text, n_best)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_text\u001b[38;5;241m.\u001b[39msplit()):\n\u001b[1;32m----> 5\u001b[0m     x[\u001b[38;5;241m0\u001b[39m,i,\u001b[43munique_token_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m predictions\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(x)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'allwillhavetolookintothisthingandall'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAll will have to look into this thing and all\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(input_text, text_length, creativity)\u001b[0m\n\u001b[0;32m      7\u001b[0m     choice \u001b[38;5;241m=\u001b[39m unique_tokens[random\u001b[38;5;241m.\u001b[39mchoice(predict_next_word(sub_sequence, creativity))]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m----> 9\u001b[0m     choice\u001b[38;5;241m=\u001b[39m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m word_sequence\u001b[38;5;241m.\u001b[39mappend(choice)\n\u001b[0;32m     11\u001b[0m current  \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\random.py:369\u001b[0m, in \u001b[0;36mRandom.choice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchoice\u001b[39m(\u001b[38;5;28mself\u001b[39m, seq):\n\u001b[0;32m    368\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seq:\n\u001b[0;32m    370\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot choose from an empty sequence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m seq[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow(\u001b[38;5;28mlen\u001b[39m(seq))]\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "generate_text(\"All will have to look into this thing and all\",100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b98ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7b943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aimodelvenv",
   "language": "python",
   "name": "aimodelvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
